{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "下面是对使用LangChain进行信息提取链的步骤逐步解释，每个步骤后都有详细的说明和必要的类比，帮助更好地理解。\n",
    "\n",
    "### 1. 设置环境\n",
    "\n",
    "#### 1.1 安装LangChain\n",
    "你需要先安装LangChain库。可以使用以下命令通过pip或conda进行安装：\n",
    "```bash\n",
    "pip install langchain\n",
    "```\n",
    "或者\n",
    "```bash\n",
    "conda install langchain -c conda-forge\n",
    "```\n",
    "\n",
    "这种安装步骤类似于你在厨房准备做饭，首先需要确保所有的工具和食材都准备好。\n",
    "\n",
    "### 2. 定义Schema（模式）\n",
    "\n",
    "#### 2.1 使用Pydantic定义Schema\n",
    "你需要定义一个模式（schema），描述你想从文本中提取的信息。这就像设计一个模具，告诉机器要提取哪些具体的信息。以下是一个示例，用于提取个人信息：\n",
    "```python\n",
    "from typing import Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(default=None, description=\"The color of the person's hair\")\n",
    "    height_in_meters: Optional[str] = Field(default=None, description=\"Height measured in meters\")\n",
    "```\n",
    "\n",
    "这里的`Optional`表示这个字段是可选的，这样模型在没有足够信息时可以返回`None`，而不是编造一个值。\n",
    "\n",
    "一种容易理解的方式描述，也许可以使用日常类比：\n",
    "想象一下你在填写一个表格，这个表格有多个字段，例如名字、发色和身高。如果你不知道某个字段的信息，你可以留空。这里的模式就像是这个表格的模板。\n",
    "\n",
    "### 3. 创建提取器\n",
    "\n",
    "#### 3.1 定义提示模板（Prompt Template）\n",
    "提示模板告诉语言模型如何提取信息。我们使用以下代码来定义一个简单的提示模板：\n",
    "```python\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert extraction algorithm. Extract relevant information from the text. If an attribute is unknown, return null.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "```\n",
    "\n",
    "这种提示模板类似于给机器下达一个明确的任务指令：你是一个信息提取专家，从文本中提取相关信息，如果某个属性未知，就返回空值。\n",
    "\n",
    "一种容易理解的方式描述，也许可以使用日常类比：\n",
    "想象你是一个调查员，老板告诉你：“如果你在调查中遇到某些信息，不确定的话就不要乱填，直接标注为空。”\n",
    "\n",
    "#### 3.2 创建可运行对象（Runnable）\n",
    "使用上面的提示模板和语言模型来创建一个可运行的提取器：\n",
    "```python\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "runnable = prompt | llm.with_structured_output(schema=Person)\n",
    "```\n",
    "\n",
    "这里的`runnable`表示一个可以运行的链条，结合了提示模板和语言模型。\n",
    "\n",
    "### 4. 调用链条\n",
    "\n",
    "#### 4.1 测试提取链条\n",
    "提供一些文本并调用链条进行测试：\n",
    "```python\n",
    "text = \"Alan Smith is 6 feet tall and has blond hair.\"\n",
    "result = runnable.invoke({\"text\": text})\n",
    "print(result)\n",
    "# Output: Person(name='Alan Smith', hair_color='blond', height_in_meters='1.8288')\n",
    "```\n",
    "\n",
    "这里我们输入了一些文本，并使用我们定义的链条进行信息提取。结果是一个`Person`对象，包含提取的信息。\n",
    "\n",
    "一种容易理解的方式描述，也许可以使用日常类比：\n",
    "这就像是你向一个智能助手描述一个人，并让它告诉你这个人的详细信息。\n",
    "\n",
    "### 5. 提取多个实体\n",
    "\n",
    "#### 5.1 定义嵌套模式\n",
    "为了提取多个实体，可以使用嵌套模型。以下是一个示例：\n",
    "```python\n",
    "from typing import List\n",
    "\n",
    "class Data(BaseModel):\n",
    "    people: List[Person]\n",
    "\n",
    "runnable = prompt | llm.with_structured_output(schema=Data)\n",
    "text = \"Jeff has black hair and is 6 feet tall. Anna has the same hair color.\"\n",
    "result = runnable.invoke({\"text\": text})\n",
    "print(result)\n",
    "# Output: Data(people=[Person(name='Jeff', hair_color='black', height_in_meters='1.8288'), Person(name='Anna', hair_color='black', height_in_meters=None)])\n",
    "```\n",
    "\n",
    "这种嵌套模式允许提取多个实体的信息。\n",
    "\n",
    "一种容易理解的方式描述，也许可以使用日常类比：\n",
    "想象你在一个派对上遇到几个人，记下了每个人的名字和一些信息，现在你需要把这些信息整理成一个列表。\n",
    "\n",
    "### 6. 提高性能\n",
    "\n",
    "#### 6.1 使用参考示例\n",
    "通过使用参考示例和最佳实践，可以提高提取质量。提供详细的文档和可选属性，以防止模型生成错误信息。\n",
    "\n",
    "这种提高性能的步骤类似于在调查前先进行培训，确保调查员知道如何处理各种情况，以提高信息的准确性。\n",
    "\n",
    "通过这些步骤，你可以使用LangChain构建一个强大的信息提取链条，自动从文本中提取结构化信息。"
   ],
   "id": "aa75abbe1d7b92be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "54e043ad640996fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
